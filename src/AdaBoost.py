# -*- coding: utf-8 -*-
"""Algorithms 44f457

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/#fileId=https%3A//storage.googleapis.com/kaggle-colab-exported-notebooks/algorithms-44f457-f17a3b10-8435-4597-b232-9447237361db.ipynb%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com/20240504/auto/storage/goog4_request%26X-Goog-Date%3D20240504T062122Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D390c5ff05345a60d047bfe837a0ebbddfcf86c318f5a28646f2464b194c25456d7d25942dd5c95931720c4b1a070a3b0e4e6844bf2c7adadf8aed0257218e0a4c117952957ae308009857497f512112c96eaec3c5b92c41d29cf427a98cd216468c12e9126180d379859eebd24485d12ed7f4f78ee608df974fce57ab39c8267055d687343286b90aa8afc7ca03552f6998b2a7bdce8866f230abce74e6c4bdc26a507017fc3cc1d929a8b1c597d4b61cd45246afba58ed072b693f92499e994c7f5748db4f2c28d783a9db577cc086cd0e8bf110b9ff037e5b2365e8ea7f50a706bc545880a77464fee47173316c91053f31c5ab0c44d999f4f9748fa348636
"""

import os,gc
os.environ["CUDA_VISIBLE_DEVICES"]="0,1"
import pandas as pd, numpy as np
import matplotlib.pyplot as plt
import warnings

warnings.filterwarnings('ignore')

PATH = '/kaggle/input/hms-harmful-brain-activity-classification/'
df = pd.read_csv(PATH + 'train.csv')
TARGETS = df.columns[-6:]
print('Train shape:', df.shape )
print('Targets', list(TARGETS))
df.head()

train = df.groupby('eeg_id')[['spectrogram_id','spectrogram_label_offset_seconds']].agg(
    {'spectrogram_id':'first','spectrogram_label_offset_seconds':'min'})
train.columns = ['spectrogram_id','min']

tmp = df.groupby('eeg_id')[['spectrogram_id','spectrogram_label_offset_seconds']].agg(
    {'spectrogram_label_offset_seconds':'max'})
train['max'] = tmp

tmp = df.groupby('eeg_id')[['patient_id']].agg('first')
train['patient_id'] = tmp

tmp = df.groupby('eeg_id')[TARGETS].agg('sum')
for t in TARGETS:
    train[t] = tmp[t].values

y_data = train[TARGETS].values
y_data = y_data / y_data.sum(axis=1,keepdims=True)
train[TARGETS] = y_data

tmp = df.groupby('eeg_id')[['expert_consensus']].agg('first')
train['target'] = tmp

train = train.reset_index()
print('Train non-overlapp eeg_id shape:', train.shape )
train.head(5)

EEG_PATH = PATH + 'train_eegs/'

row = train.iloc[1]
eeg_id = row['eeg_id']

eeg_file_path = os.path.join(EEG_PATH, f'{eeg_id}.parquet')
sample_eeg_data = pd.read_parquet(eeg_file_path)
sample_eeg_data = sample_eeg_data.iloc[:, :-1]
sample_eeg_data = sample_eeg_data.iloc[:, [col for col in range(sample_eeg_data.shape[1]) if col not in [8, 9, 10]]]

start_time_point = int((sample_eeg_data.shape[0] - 10_000) // 2)

eeg_slice = sample_eeg_data.iloc[start_time_point : start_time_point + 10_000, :]

eeg_slice

FLAG = True

if FLAG:
    fs = 200
    EEG_PATH = PATH + 'train_eegs/'
    all_eeg_data = np.zeros((len(train), 10000, 19))

    for row_idx in range(len(train)):
        print(row_idx, end = ", ")
        row = train.iloc[row_idx]
        eeg_id = row['eeg_id']

        eeg_file_path = os.path.join(EEG_PATH, f'{eeg_id}.parquet')
        eeg_data = pd.read_parquet(eeg_file_path)
        eeg_data = eeg_data.iloc[:, :-1]
        #eeg_data = eeg_data.iloc[:, [col for col in range(eeg_data.shape[1]) if col not in [8, 9, 10]]]
        start_time_point = int((eeg_data.shape[0] - 10_000) // 2)

        eeg_slice = eeg_data.iloc[start_time_point : start_time_point + 10_000, :]

        all_eeg_data[row_idx, :, :] = eeg_slice

    print("Shape of all_eeg_data:", all_eeg_data.shape)
else:
    print("FLAG is set to False. The code below is not executed.")

"""# Feature Extraction"""

import scipy.stats

def extract_eeg_features(eeg_data):
    """
    Extract features from EEG data, including LL Spec, LP Spec, RP Spec, RL Spec

    Parameters:
    - eeg_data: EEG data with shape (number of samples, time points, number of electrodes)

    Returns:
    - Feature matrix with shape (number of samples, number of features)
    """
    # Initialize the feature matrix
    num_samples, num_time_points, num_electrodes = eeg_data.shape
    num_features = 8 * num_electrodes  # Mean, standard deviation, minimum, maximum, skewness, kurtosis, energy, entropy for each electrode + 4 global features
    features = np.zeros((num_samples, num_features))

    # Extract features
    for sample_idx in range(num_samples):
        for electrode_idx in range(num_electrodes):
            electrode_data = eeg_data[sample_idx, :, electrode_idx]
            feature_idx = electrode_idx * 8

            # Mean
            features[sample_idx, feature_idx] = np.mean(electrode_data)
            # Standard deviation
            features[sample_idx, feature_idx + 1] = np.std(electrode_data)
            # Minimum
            features[sample_idx, feature_idx + 2] = np.min(electrode_data)
            # Maximum
            features[sample_idx, feature_idx + 3] = np.max(electrode_data)
            # Skewness
            features[sample_idx, feature_idx + 4] = scipy.stats.skew(electrode_data)
            # Kurtosis
            features[sample_idx, feature_idx + 5] = scipy.stats.kurtosis(electrode_data)
            # Energy
            features[sample_idx, feature_idx + 6] = np.sum(electrode_data**2) / len(electrode_data)
            # Entropy
            features[sample_idx, feature_idx + 7] = scipy.stats.entropy(np.abs(electrode_data))
        # Additional features: LL Spec, LP Spec, RP Spec, RL Spec
        ll_spec = (np.abs(np.fft.fft(eeg_data[sample_idx, :, 0] - eeg_data[sample_idx, :, 4]))**2 +
                   np.abs(np.fft.fft(eeg_data[sample_idx, :, 4] - eeg_data[sample_idx, :, 5]))**2 +
                   np.abs(np.fft.fft(eeg_data[sample_idx, :, 5] - eeg_data[sample_idx, :, 6]))**2 +
                   np.abs(np.fft.fft(eeg_data[sample_idx, :, 6] - eeg_data[sample_idx, :, 7]))**2) / 4
        features[sample_idx, -4] = np.mean(ll_spec)

        lp_spec = (np.abs(np.fft.fft(eeg_data[sample_idx, :, 0] - eeg_data[sample_idx, :, 1]))**2 +
                   np.abs(np.fft.fft(eeg_data[sample_idx, :, 1] - eeg_data[sample_idx, :, 2]))**2 +
                   np.abs(np.fft.fft(eeg_data[sample_idx, :, 2] - eeg_data[sample_idx, :, 3]))**2 +
                   np.abs(np.fft.fft(eeg_data[sample_idx, :, 3] - eeg_data[sample_idx, :, 7]))**2) / 4
        features[sample_idx, -3] = np.mean(lp_spec)

        rp_spec = (np.abs(np.fft.fft(eeg_data[sample_idx, :, 8] - eeg_data[sample_idx, :, 9]))**2 +
                   np.abs(np.fft.fft(eeg_data[sample_idx, :, 9] - eeg_data[sample_idx, :, 10]))**2 +
                   np.abs(np.fft.fft(eeg_data[sample_idx, :, 10] - eeg_data[sample_idx, :, 11]))**2 +
                   np.abs(np.fft.fft(eeg_data[sample_idx, :, 11] - eeg_data[sample_idx, :, 15]))**2) / 4
        features[sample_idx, -2] = np.mean(rp_spec)

        rl_spec = (np.abs(np.fft.fft(eeg_data[sample_idx, :, 8] - eeg_data[sample_idx, :, 12]))**2 +
                   np.abs(np.fft.fft(eeg_data[sample_idx, :, 12] - eeg_data[sample_idx, :, 13]))**2 +
                   np.abs(np.fft.fft(eeg_data[sample_idx, :, 13] - eeg_data[sample_idx, :, 14]))**2 +
                   np.abs(np.fft.fft(eeg_data[sample_idx, :, 14] - eeg_data[sample_idx, :, 15]))**2) / 4
        features[sample_idx, -1] = np.mean(rl_spec)
    return features

import numpy as np
import scipy

from scipy.stats import skew, kurtosis
from scipy.stats.mstats import moment
from sklearn.preprocessing import StandardScaler

if FLAG:
    extracted_features = extract_eeg_features(all_eeg_data)
    print("Shape of extracted features:", extracted_features.shape)
else:
    print("FLAG is set to False. The code below is not executed.")

if FLAG:
    mean_values = np.nanmean(extracted_features, axis=0)
    nan_indices = np.isnan(extracted_features)
    extracted_features[nan_indices] = np.take(mean_values, nan_indices.nonzero()[1])
    print("Shape of eeg_features after replacing NaN values:", extracted_features.shape)
    save_path = '/kaggle/working/extracted_eeg_features.npy'
    np.save(save_path, extracted_features)
    print(f"Extracted EEG features saved at: {save_path}")
else:
    extracted_features = np.load('/kaggle/input/8-basic-feaatures-with-eeg/extracted_eeg_features (1).npy')
    print("Shape of extracted features:", extracted_features.shape)

ef = pd.DataFrame(extracted_features)
ef

"""# Label"""

train_copy = train.copy()
ycol = [c for c in train_copy.columns if c in ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']]
cd = {'Seizure':'seizure_vote', 'GPD':'gpd_vote', 'LRDA':'lrda_vote', 'Other':'other_vote', 'GRDA':'grda_vote', 'LPD':'lpd_vote'}
train_copy['target'] = train_copy['target'].map(cd)
for i in range(len(train_copy)):
    c = train_copy['target'][i]
    train_copy[c][i] = train_copy[c][i]+10 #adding weight to expert consensus

ysum = train_copy[ycol].sum(axis=1)
for c in ycol:
    train_copy[c] = (train_copy[c] / ysum).astype(np.float64)

label = train_copy[ycol]
label.shape

"""# Model"""

ef

# Standardize the extracted features
scaler = StandardScaler()
standardized_features = scaler.fit_transform(extracted_features)

# Convert the standardized features back to a DataFrame if needed
standardized_ef = pd.DataFrame(standardized_features)

# Display the shape of standardized features
print("Shape of standardized features:", standardized_ef.shape)

standardized_ef

"""# **AdaBoost**"""

import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

X = standardized_features
y_labels = np.argmax(label.values, axis=1)
X_train, X_test, y_train, y_test = train_test_split(X, y_labels, test_size=0.2, random_state=42)

from sklearn.ensemble import AdaBoostClassifier
from sklearn.metrics import roc_curve, auc, mean_squared_error, mean_absolute_error, precision_score, recall_score, f1_score

# Initialize AdaBoostClassifier
adaboost_clf = AdaBoostClassifier(n_estimators=1000,
                                  learning_rate=0.05,
                                  random_state=42)

# Train the model
adaboost_clf.fit(X_train, y_train)

# Predict
y_pred_adaboost = adaboost_clf.predict(X_test)

# Calculate MSE and MAE
mse_adaboost = mean_squared_error(y_test, y_pred_adaboost)
mae_adaboost = mean_absolute_error(y_test, y_pred_adaboost)

# Accuracy
accuracy_adaboost = accuracy_score(y_test, y_pred_adaboost)

# Precision
precision_adaboost = precision_score(y_test, y_pred_adaboost, average='macro')

# Recall
recall_adaboost = recall_score(y_test, y_pred_adaboost, average='macro')

# F1-score
f1_adaboost = f1_score(y_test, y_pred_adaboost, average='macro')

# Print the results
print("Metrics for AdaBoost:")
print(f"Mean Squared Error (MSE): {mse_adaboost}")
print(f"Mean Absolute Error (MAE): {mae_adaboost}")
print(f"Accuracy: {accuracy_adaboost}")
print(f"Precision: {precision_adaboost}")
print(f"Recall: {recall_adaboost}")
print(f"F1-score: {f1_adaboost}")

from sklearn.metrics import confusion_matrix, classification_report
# Predict probabilities
y_probs_adaboost = adaboost_clf.predict_proba(X_test)

# Plot ROC curve for each class
fpr_adaboost = dict()
tpr_adaboost = dict()
roc_auc_adaboost = dict()
for i in range(len(np.unique(y_labels))):
    fpr_adaboost[i], tpr_adaboost[i], _ = roc_curve(y_test == i, y_probs_adaboost[:, i])
    roc_auc_adaboost[i] = auc(fpr_adaboost[i], tpr_adaboost[i])

plt.figure(figsize=(10, 8))
for i in range(len(np.unique(y_labels))):
    plt.plot(fpr_adaboost[i], tpr_adaboost[i], label=f'Class {i} (AUC = {roc_auc_adaboost[i]:.2f})')
plt.plot([0, 1], [0, 1], 'k--', lw=2)
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC-AUC Curve for Each Class (AdaBoost)')
plt.legend(loc="lower right")
plt.show()

import seaborn as sns
from sklearn.metrics import classification_report

# Convert class labels to strings
class_names = [str(label) for label in np.unique(y_labels)]
print(f"Accuracy (AdaBoost): {accuracy_adaboost}")

# Confusion Matrix
conf_mat_adaboost = confusion_matrix(y_test, y_pred_adaboost)
plt.figure(figsize=(10, 8))
sns.heatmap(conf_mat_adaboost, annot=True, fmt='d', cmap='Blues', xticklabels=np.unique(y_labels), yticklabels=np.unique(y_labels))
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix (AdaBoost)')
plt.show()

# Classification Report
print(classification_report(y_test, y_pred_adaboost, target_names=class_names))

"""# Infer Test and Create Submission CSV"""

test = pd.read_csv('/kaggle/input/hms-harmful-brain-activity-classification/test.csv')
print('Test shape',test.shape)
test.head()

# FEATURE ENGINEER TEST
PATH2 = '/kaggle/input/hms-harmful-brain-activity-classification/test_eegs/'
data_test = np.zeros((len(test), extracted_features.shape[1]))
test_eeg = np.zeros((len(test), 10000, 19))

for k in range(len(test)):
    row = test.iloc[k]
    s = int(row.eeg_id)
    eeg_test = pd.read_parquet(f'{PATH2}{s}.parquet')
    eeg_test = eeg_test.iloc[:, :-1]
    #eeg_test = eeg_test.iloc[:, [col for col in range(eeg_test.shape[1]) if col not in [8, 9, 10]]]
    start_time_point = int((eeg_test.shape[0] - 10_000) // 2)
    eeg_test_slice = eeg_test.iloc[start_time_point : start_time_point + 10_000, :]

    test_eeg[k, :, :] = eeg_test_slice
    features_test = extract_eeg_features(test_eeg)
    print("Shape of features_test:", features_test.shape)
    data_test = features_test
print("Shape of data_test:", data_test.shape)

predictions_proba = adaboost_clf.predict_proba(data_test)
class_names = ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']
probabilities_df = pd.DataFrame(predictions_proba, columns=class_names)
print(probabilities_df.head(1))

sub = pd.DataFrame({'eeg_id':test.eeg_id.values})
sub[TARGETS] = probabilities_df
sub.to_csv('submission.csv',index=False)
print('Submissionn shape',sub.shape)
sub.head()

# SANITY CHECK TO CONFIRM PREDICTIONS SUM TO ONE
sub.iloc[:,-6:].sum(axis=1)

